{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4218e7d7",
   "metadata": {},
   "source": [
    "# Linear, ridge, and lasso regression example\n",
    "\n",
    "Using the same dataset, we'll train three models using different regressions and inspect the outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480f463",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5504755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22487675",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decc285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset comes from a database of baseball players. All columns are features, except the 'salary' wich will be the target.\n",
    "data = pd.read_csv('data/hitters.csv')\n",
    "df_hitters = data.copy()\n",
    "df_hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79486bda-960c-4040-aabe-5b4c15b9bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more information on each column (you can also open the file in excel)\n",
    "df_legend = pd.read_excel('data/hitters_legend.xlsx')\n",
    "df_legend.head(26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fe36d-20e5-43a0-ba84-f806b57e6fe0",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7db941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "print('The league types are:', df_hitters['League'].unique())\n",
    "print('The divison types are:', df_hitters['Division'].unique())\n",
    "print('The new league options are:', df_hitters['NewLeague'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hitters_num = pd.get_dummies(df_hitters, columns = ['League', 'Division', 'NewLeague'], drop_first=True)\n",
    "df_hitters_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f59a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are NaN values\n",
    "df_hitters_num.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll drop the rows with null salary, but we'll fill them afterwards with the predictions from our models\n",
    "df_hitters_num_nonull = df_hitters_num.dropna()\n",
    "df_hitters_num_nonull.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9657090-a94e-4124-8190-4311cc146ce3",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e37db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution\n",
    "# We can infer that all values above 1500 are outliers\n",
    "sns.displot(df_hitters_num_nonull['Salary']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84290119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between the dependent (target) and independent (features) variables\n",
    "# Seems like the stronger correlations are in the career player stats (bottom columns that start with a C) \n",
    "correlation = df_hitters_num_nonull.corr()\n",
    "correlation['Salary'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a00120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multicollinearity between the independent variables\n",
    "# There's a lot of multicolinearity between the variables (all the darker blue squares)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(df_hitters.corr(),\n",
    "            vmin = -1, \n",
    "            vmax = 1,\n",
    "            cmap =\"GnBu\",\n",
    "            annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7526ba",
   "metadata": {},
   "source": [
    "## Declare the dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db887284",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_hitters_num_nonull.drop('Salary', axis = 1)\n",
    "y = df_hitters_num_nonull['Salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e75c6",
   "metadata": {},
   "source": [
    "## Split the data into training and testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want the algorithm to interpret all variables equally, so we must standardize\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195abbf",
   "metadata": {},
   "source": [
    "## Perform linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac19b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_y_pred = lin_reg.predict(X_test)\n",
    "lin_reg_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047235a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_comp = pd.DataFrame({'Predicted': lin_reg_y_pred, 'Actual': y_test})\n",
    "lin_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear Regression Model RMSE is: \", math.sqrt(mean_squared_error(y_test, lin_reg_y_pred)))\n",
    "print(\"Linear Regression Model Training Score: \",lin_reg.score(X_train, y_train))\n",
    "print(\"Linear Regression Model Testing Score: \",lin_reg.score(X_test, y_test))\n",
    "\n",
    "# There's a big difference between the predicted and real values, and the testing score is much lower than the \n",
    "# training one, most certainly due to multicollinearity or overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6300bd",
   "metadata": {},
   "source": [
    "## Perform ridge regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959049b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RepeatedKFold repeats a procedure multiple times and outputs the mean result\n",
    "# n_splits represents the number of folds (a fold is a random subset of the training data)\n",
    "# this will give us the best value for our tuning parameter\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ridge regressor\n",
    "# alphas is the penalty term, we're specifying a range from 0.1 to 10, with a step of 0.1\n",
    "ridge = RidgeCV(alphas=np.arange(0.1, 10, 0.1), cv=cv, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a62f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the ridge regressor\n",
    "ridge.fit(X_train,y_train)\n",
    "ridge_reg_y_pred = ridge.predict(X_test)\n",
    "\n",
    "print(\"Ridge tuning parameter:\", (ridge.alpha_))\n",
    "print (\"Ridge model coefficients:\", (ridge.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge Regression Model RMSE is: \", math.sqrt(mean_squared_error(y_test, ridge_reg_y_pred)))\n",
    "print(\"Ridge Regression Model Training Score: \",ridge.score(X_train, y_train))\n",
    "print(\"Ridge Regression Model Testing Score: \",ridge.score(X_test, y_test))\n",
    "\n",
    "# It performed slightly better than the linear model, but it's still weak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d5daf7",
   "metadata": {},
   "source": [
    "## Perform lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the lasso regressor\n",
    "lasso = LassoCV(alphas=np.arange(0.1, 10.0, 0.1), cv=cv, tol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ab278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the lasso regressor\n",
    "lasso.fit(X_train,y_train)\n",
    "lasso_reg_y_pred = lasso.predict(X_test)\n",
    "\n",
    "print(\"Lasso tuning parameter:\", (lasso.alpha_))\n",
    "print (\"Lasso model coefficients:\", (lasso.coef_))\n",
    "\n",
    "# Notice that some coeficients dropped to zero, meaning that the Lasso dropped some features (as we've talked about in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso Regression Model RMSE is: \", math.sqrt(mean_squared_error(y_test, lasso_reg_y_pred)))\n",
    "print(\"Lasso Regression Model Training Score: \",lasso.score(X_train, y_train))\n",
    "print(\"Lasso Regression Model Testing Score: \",lasso.score(X_test, y_test))\n",
    "\n",
    "# Lasso sits between the previous models: it performed better than Linear but worse than Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e742f",
   "metadata": {},
   "source": [
    "## Compare the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e21a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear Regression Model Training Score: \",lin_reg.score(X_train, y_train))\n",
    "print(\"Linear Regression Model Testing Score: \",lin_reg.score(X_test, y_test))\n",
    "print(\"Ridge Regression Model Training Score: \",ridge.score(X_train, y_train))\n",
    "print(\"Ridge Regression Model Testing Score: \",ridge.score(X_test, y_test))\n",
    "print(\"Lasso Regression Model Training Score: \",lasso.score(X_train, y_train))\n",
    "print(\"Lasso Regression Model Testing Score: \",lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30763c39",
   "metadata": {},
   "source": [
    "## Root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fff75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Linear Regression Model RMSE is: \", math.sqrt(mean_squared_error(y_test, lin_reg_y_pred)))\n",
    "print(\"Ridge Regression Model RMSE is: \", math.sqrt(mean_squared_error(y_test, ridge_reg_y_pred)))\n",
    "print(\"Lasso Regression Model RMSE is: \", math.sqrt(mean_squared_error(y_test, lasso_reg_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bba971",
   "metadata": {},
   "source": [
    "## Replacing the missing values in the DataFrame\n",
    "\n",
    "Remember when we dropped the rows with a missing salary? We'll now predict those values using the model that performed better, Ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hitters_nan = df_hitters_num[df_hitters_num['Salary'].isnull()]\n",
    "df_hitters_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a08e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nan = df_hitters_nan.drop('Salary', axis = 1)\n",
    "y_nan = df_hitters_nan['Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_nan = scaler.fit_transform(X_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163035a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_pred = ridge.predict(X_nan)\n",
    "nan_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03302f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_hitters_nan.drop(['Salary'], axis=1)\n",
    "df_nan_full = df_hitters_nan.copy()\n",
    "df_nan_full['Salary'] = nan_pred\n",
    "df_nan_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
